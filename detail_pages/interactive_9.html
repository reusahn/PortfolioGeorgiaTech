<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Choi Jung-hoon AI Human Research Project</title>
  <style>
  @media (max-width: 768px) {
    .hide-on-mobile {
      display: none;
    }
  }
    body {
      margin: 0;
      font-family: 'Helvetica Neue', sans-serif;
      background: #000;
      color: #f0f0f0;
      line-height: 1.7;
      padding: 60px 20px;
    }
    .nav {
      position: fixed;
      top: 20px;
      right: 20px;
      font-size: 0.9rem;
      z-index: 1000;
    }
    .nav a {
      margin-left: 15px;
      text-decoration: none;
      color: #888;
    }
    .nav a:hover {
      color: #fff;
    }
    .container {
      max-width: 900px;
      margin: 0 auto;
    }
    h1 {
      font-size: 2.5rem;
      font-weight: 700;
      margin-bottom: 10px;
      color: #fff;
    }
    .meta {
      font-size: 0.95rem;
      color: #999;
      font-style: italic;
      margin-bottom: 30px;
    }
    .video-container {
      width: 100%;
      aspect-ratio: 16 / 9;
      margin-bottom: 30px;
    }
    .video-container iframe {
      width: 100%;
      height: 100%;
      border: none;
      border-radius: 8px;
    }
    .description {
      font-size: 1rem;
      color: #ccc;
      margin-bottom: 50px;
    }
    .image-text-block {
      display: flex;
      flex-direction: row;
      gap: 30px;
      align-items: flex-start;
      margin-bottom: 60px;
      flex-wrap: wrap;
    }
    .image-text-block img {
      width: 100%;
      max-width: 400px;
      border-radius: 8px;
    }
    .image-text-block .text {
      flex: 1;
      min-width: 250px;
      font-size: 0.95rem;
      color: #aaa;
    }
    nav.pagination {
      margin-top: 60px;
      display: flex;
      justify-content: space-between;
      font-size: 0.95rem;
    }
    nav.pagination a {
      color: #888;
      text-decoration: none;
    }
    nav.pagination a:hover {
      color: #fff;
    }
  </style>
</head>
<body>
  <div class="nav">
    <a href="../index.html#film">Film</a>
    <a href="../index.html#interactive">Interactive Art</a>
    <a href="../index.html#media">Media Art</a>
    <a href="../index.html#xr">XR</a>
    <a href="../index.html#vfx">3D/VFX</a>
    <a href="../index.html#about" class="hide-on-mobile">About</a>
    <a href="../index.html#news" class="hide-on-mobile">News</a>
  </div>

  <div class="container">
    <h1>Choi Jung-hoon AI Human Research Project (JANNABI AI Digital Human)</h1>
    <div class="meta">2024 · Digital Human Research · California Institute of the Arts</div>

    <!-- Video -->
    <div class="video-container">
      <iframe src="https://player.vimeo.com/video/933305770?h=b3cef8f513" 
              allow="autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share">
      </iframe>
    </div>

    <div class="description">

      <h4>Overview</h4>
      <p>
      Choi Jung-hoon AI Human reconstructs the lead vocalist of JANNABI as a generative, interactive AI digital human.
      The project examines how identity, emotion, and authorship can be algorithmically simulated, transforming a figure of admiration into computational presence.
      Through real-time speech, gesture response, and persona-driven interaction, the AI explores the blurry line between replication and authenticity.
      </p>

      <h4>Research Context</h4>
      <p>
      In an era where fandom, data, and simulation overlap, the project asks:
      <i>“When emotion becomes code, can affection survive imitation?”</i><br><br>
      By reconstructing an admired artist, the work reframes parasocial devotion as a research methodology.
      The digital performer learns, speaks, and responds, turning fandom into feedback and making visible the emotional projection that fuels AI-human intimacy.
      </p>

      <h4>Digital Human Construction</h4>
      <p>
      High-resolution portrait input → Character Creator 4 Headshot → ZBrush refinement → Maya rigging and UV workflow → Unity real-time rendering.
      </p>
      <div class="image-text-block">
        <img src="../assets/images/ChoiJungHoon_AI_01.jpg" />
        <img src="../assets/images/ChoiJungHoon_AI_02.jpg" />
      </div>

      <h4>Voice Cloning (ElevenLabs)</h4>
      <p>
      Interview and performance samples were processed through ElevenLabs Instant Voice Cloning,
      enabling spontaneous speech generation that mimics Choi Jung-hoon’s tone, color, and cadence.
      Real-time lip-sync was achieved through blendshape animation in Unity.
      </p>

      <h4>Conversational AI Integration</h4>
      <p>
      A GPT-based persona model was embedded into Unity.  
      Audience speech → transcription → GPT response → ElevenLabs TTS → real-time facial animation.<br>
      A coroutine-based pipeline ensured continuous, natural conversational flow.
      </p>

      <h4>Sensor-Based Interaction (Azure Kinect)</h4>
      <p>
      Azure Kinect provided body tracking, gesture detection, and depth information, allowing the AI human to react physically to visitors—leaning, nodding, and mirroring engagement.
      Audience forms were rendered as 3D point clouds, visualizing how AI perceives human presence.
      </p>

      <h4>Real-Time Unity Integration</h4>
      <p>
      All systems—speech, gesture, persona, emotional response, shaders—were unified in Unity’s real-time rendering pipeline,
      emphasizing digital fragility and emotional realism.
      </p>

      <div class="image-text-block">
        <img src="../assets/images/ChoiJungHoon_AI_03.jpg" />
        <!-- <img src="./media/ChoiJungHoon_AI_04.jpg" />
        <img src="../assets/images/ChoiJungHoon_AI_05.jpg" />-->
        <img src="../assets/images/ChoiJungHoon_AI_06.jpg" />
        <img src="../assets/images/ChoiJungHoon_AI_07.jpg" />
        <img src="../assets/images/ChoiJungHoon_AI_08.jpg" />
      </div>

      <h4>Artistic & Theoretical Focus</h4>
      <p>
      The project explores AI-mediated affection and the co-construction of identity in machine-human systems.
      By merging machine learning, motion capture, and emotional projection, the digital Choi Jung-hoon becomes both a subject of empathy and a simulation of it.
      This work rethinks authorship and digital intimacy in the era of computational performers.
      </p>

      <h4>Keywords</h4>
      <p>
      #digital-human #ai-persona #voice-cloning #real-time-interaction #cyborg-psychology
      </p>

      <h4>Credits</h4>
      <p>
      Principal Investigator / Technical Director: <b>Jonghoon Ahn</b><br>
      Institution: California Institute of the Arts<br>
      Tools: Unity, Character Creator 4, ZBrush, Maya, ElevenLabs, Azure Kinect, GPT API
      </p>

    </div>

    <nav class="pagination">
      <a href="interactive_1.html">← Previous</a>
      <a href="../index.html">Back to Portfolio</a>
      <a href="interactive_3.html">Next →</a>
    </nav>
  </div>
</body>
</html>
